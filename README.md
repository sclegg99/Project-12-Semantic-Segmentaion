# Semantic Segmentation

## Objective
The objective is to develop a Neural Network (NN) that will identify the region in an image that is the road surface.  A semantic segmentation method based on the work of Long et. al ("Fully Convolution Networks for Semantic Segmentation", IEEE Transactions on Pattern Analysis and Machine Intelligence, Volume: 39, Issue: 4, April 1 2017) was employed.

### Introduction
A NN was designed and trained to classify image pixels as road or not road.  The NN uses a Fully Convolutional Network (FCN) composed of a encoder followed by a decoder.  The VGG16 frozen NN was chosen as the encoder.  The last layer of the VGG16 is a fully connected layer.  This layer was decapitate and replace with a 1x1 convolution when then feed into the decoder layers.  The decoder layers were composed of a combination of pooling and convolutional transposes that result in an upsampling of the image with pixel level classification.  Figure 1 graphically illustrates this FCN. ![Figure 1](figures/VGG-Model.png?raw=true)

The final architecture of the NN is illustrated in Figure 2.  This figure shows the VGG16 encoder on the left hand side while the pooling and convolutional transpose operation of illustrated on the right hand side of the figure.  The encoder extracted the encoder data from the pooling output of layers three and four as well as the data just prior to the last (that is, fully connected) layer. The data from each of these layers is processed as follows:
1. The output of the 1x1 convolution is upsampled (layers.conv2d_transpose) with a kernel size of 4 and step size of 2.
2. VGG16 layer 4 pooled output is added to the output of step 1.
3. Step 2 output is upsampled with a kernel size of 4 and step size of 2.
4. VGG16 layer 3 pooled output is added to the output of step 3.
5. Step 4 output is upsampled with a kernel size of 8 and step size of 4.
6. A softmax function is applied to the output of step 5.
7. If the softmax result exceeds 0.5 then the pixel is classified as road.
![Figure 2](figures/TensorGraph.png?raw=true)
This decoder follows the method outlined in the Long et al. paper where it was found that additional decoder layers only marginally improved the predictive capability of the NN.

### Training
The Kitti Road dataset was used to train the NN.  This dataset consisted of 289 paired images.  The image pairs consisted of the raw image and the second was a ground truth image.  Figures 3 and 4 illustrate the raw image and ground truth image. Ground truth has been generated by manual annotation of the raw images where the pink represents the road ground truth.
![Figure 3](figures/um_000000.png?raw=true)

![Figure 4](figures/um_road_000000.png?raw=true)

A second Kitti dataset was explored which trained the NN to identify the ego lane.  A total of 96 image pairs were available for this traing.  Figure 5 illustrates the ground truth for an ego lane.
![Figure 5](figures/um_lane_000000.png?raw=true)

The NN was trained using cross entropy loss function and Adam optimizer.  Regularization employed along with a variable learning rate.  The training accuracy and IoU (intersection over union) was assessed at the end of each training epoch and the training.  Figure 6 is a plot of the IoU at the end of each epoch for the road and lane datasets.  The training accuracy was .97 and .96 at the end of training for road and lane classification, respectively.
![Figure 6](figures/IoUvsEpoch.png?raw=true)

### Testing
Once the NN was trained a frozen an optimized graph of the trained network was created using the tensor flow python tool utilities freeze_graph and optimize_for_inference.  The optimized graph was then used to infer the road (or lane) boundaries using test images available from the Kitti dataset.  Figure 7 and 8 illustrate the predicted boundaries using the optimal graph for the road and lane trained NN.
![Figure 7](figures/RoadInference.png?raw=true)

![Figure 8](figures/LaneInference.png?raw=true)
